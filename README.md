# plc-prompt-automation 

This github repository contains a lightweight Python script that drives a local Large-Language Model (LLM), via LM studio's API, through a series of parameterised prompts and logs the prompt information including the responses in JSON files for each prompt. The script was used in the master-thesis experiments on PLCOpen XML programs, in a thesis titled "TEST AMPLIFICATION AND GENERATION USING LLMS FOR INDUSTRIAL PLC CONTROL SOFTWARE". 

The script contains a config.yaml file where the user can set the LLM to be used, parameters like temperature, top_p, how many types a prompt should be repeated, max tokens, the path to the folder containing the programs, and more. The config files also contains the prompt "tasks" to be performed, such as generation, amplification by addition, and amplification by modification. Then for each task, the input needed and prompt technique (zero-shot or few-shot) are given. Alongside the prompt technique the path to the Jinja2 prompt template is provided for that prompt, which can be found in the prompts folder. The examples in the few-shot prompt templates were removed for confidentiality.

The program, automation.py, then iterates through to program root folder. This program should contain folders for each program to be tested, it expects an XML file for the source code and CSV file for the test suits. It inserts the Source code and CSV file into the prompt templates for each prompt. Then, it runs all of the prompt templates found in the config file as many times as defined in the config file. After running each prompt it stores a log file containing information about the prompt generation, the content of the prompt and the LLM prompt. The prompt logs are stored in a "results" folder inside of each program folder. The log files are automatically named to show prompt task, technique and run index of that prompt. For example a prompt that used the zero-shot technique, amplification by addition and had a run index of 2 will be named "0s-add-log2.JSON".
